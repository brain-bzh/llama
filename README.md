# ü¶ô llama ü¶ô
## A repository for the foundation day - Large Language Models slides and tutorials.
üìÑ **Presentation** 
Natural Language Processing with Llama2
- What LLMs can be useful for?
- How do LLMs work?
- Customize a LLM (RAG + Finetuning)

   
üîó link to slides:
https://docs.google.com/presentation/d/1nfV9QiNV2tbHsw9GeP7e96az-oL_C_rymTSE6V6zBos/edit?usp=sharing

üñ•Ô∏è **Tutorials** 
1. [Introduction to Sentence Embedding](sentence_embedding.ipynb)
   you can run this on google colab as well
   [![Run on Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/brain-bzh/llama/blob/main/sentence_embedding.ipynb)


3. [Retrieval Augmented Generation](LLMs_Tutorial1.ipynb) - How to use LangChain to load a PDF doc - lettre connect√©es IMT in EN pdf - and ask questions about it to llama2 
   (can't be run directly on colab because you need to download the llama 13B quantized model [here](https://drive.google.com/file/d/1afPv3HOy73BE2MoYCgYJvBDeQNa9rZbj/view) beforehand).
5. [Fine Tuning](LLMs_Tutorial2.ipynb) - How to fine tune llama 7B model on a new dataset and ask questions about it (can't be run directly on colab because you need to follow a set of preliminary steps [here](LLMs_Tutorial2_readme.txt) beforehand)..

Authors
--
Giulia Lioi, Bastien Pasdeloup

2024
